{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook is about analysis of data from [this Kaggle competition](https://www.kaggle.com/c/whats-cooking/overview)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import some important libraries here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import typing as ty\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's download and unzip our data from Kaggle:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/whats-cooking/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try to evalate some bash commands from JN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unzip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -l whats-cooking.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip whats-cooking.zip test.json.zip train.json.zip sample_submission.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['train.json', 'test.json', 'sample_submission.csv']:\n",
    "    assert i in os.listdir('./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove unnecessary .zip archives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm test.json.zip train.json.zip sample_submission.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's meet with the [most common package for working with tabular data](https://pandas.pydata.org/pandas-docs/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('./sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try to submit `sample_submissions.csv` to [Kaggle](https://www.kaggle.com/c/whats-cooking/submit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait, test, train, public, private, what's happened?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Picture about private and public dataset](https://storage.googleapis.com/kaggle-forum-message-attachments/543450/13399/Untitled.jpg \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's open json files and check shapes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_X) == 39774\n",
    "assert len(test_X) == 9944"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(test_X[0]) == dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's watch at distributions of cusines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisines_distribution = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(cuisines_distribution) == 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's vizualize using distribution plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check [Matplotlib Gallery](https://matplotlib.org/3.3.3/gallery/index.html)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Horizontal Bar Chart](https://matplotlib.org/3.3.3/gallery/lines_bars_and_markers/barh.html#sphx-glr-gallery-lines-bars-and-markers-barh-py) is what we need!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 9))\n",
    "\n",
    "<YOUR CODE>\n",
    "ax.set_yticks()\n",
    "ax.set_yticklabels()\n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "\n",
    "ax.set_xlabel('Amount of Recipes')\n",
    "ax.set_title('Comparison of cuisines by Recipes amount')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's check proportion of each cuisines in percents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's talk about Score of this Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We solve here a problem of multiclass classifiaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Multiclass problem](https://miro.medium.com/max/972/1*SwXHlCzh-d9UqHOglp3vcA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy - Pros & Cons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Multiclass Classifiaction](http://gabrielelanaro.github.io/public/post_resources/multiclass/text4384.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Acc formula](https://miro.medium.com/max/2868/1*WGK_3mj_KBZh9yTiLXGh-A.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Acc Matrix](https://miro.medium.com/max/1064/1*5XuZ_86Rfce3qyLt7XMlhw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Graphically, it is the sum of the element on the diagonal of the confusion matrix divided by the total number of predictions made**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In example above:\n",
    "\n",
    "\n",
    "accuracy = (2+2+3) / (2+2+1+2+3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(2+2+3) / (2+2+1+2+3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thus, what's the problem with Accuracy?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rus_cuisine_df = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_cuisine_df.to_csv('constant_submission_rus.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's sumbit our patriotic submission to Kaggle and check the score :)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do we have any alternatives? (In theory?)\n",
    "**Of course! But we can't choose metrics for Kaggle competition**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Precision & Recall](http://gabrielelanaro.github.io/public/post_resources/multiclass/text4385.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use another tool for analysis of texts - [WordCloud](https://github.com/amueller/word_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check Minimal Example from [official site](http://amueller.github.io/word_cloud/auto_examples/simple.html#sphx-glr-auto-examples-simple-py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Documentation with description of WordCloud as [Python object](http://amueller.github.io/word_cloud/generated/wordcloud.WordCloud.html#wordcloud.WordCloud)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_wordcloud_by_text(text, title, is_save_to_file):\n",
    "    <YOUR CODE>\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.title(title)\n",
    "    <YOUR CODE>\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_wordcloud_by_text('Hello, world! The world is on fire!', 'Example')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's concatenate all ingridients to one big string and vizualize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingridients_by_cusinies = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'Maggi' in ingridients_by_cusinies['russian']\n",
    "assert 'mayonaise' in ingridients_by_cusinies['russian']\n",
    "assert 'feta cheese crumbles' in ingridients_by_cusinies['greek']\n",
    "assert 'flat leaf parsley' in ingridients_by_cusinies['greek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for cuisine_name, ingridients_list in ingridients_by_cusinies.items():\n",
    "    <YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can use Pandas for reading json files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Pandas not only with .csv files, but also with [json](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_json.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df = pd.read_json('./train.json', encoding='utf8').set_index('id')\n",
    "test_X_df = pd.read_json('./test.json', encoding='utf8').set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_X_df.shape == (39774, 2)\n",
    "assert test_X_df.shape == (9944, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's analyze correlation between amount of ingridients per recipe and cuisine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very convenient type of plot for such analysis - [boxplot](https://en.wikipedia.org/wiki/Box_plot).\n",
    "\n",
    "[Matplotlib realization of boxplot](https://matplotlib.org/3.3.3/api/_as_gen/matplotlib.pyplot.boxplot.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's generate new feature 'amount_of_ingridients' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Maybe, [apply method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.apply.html) can help you**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df['amount_of_ingridients'] = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_X_df.iloc[14]['amount_of_ingridients'] == 12\n",
    "assert train_X_df.iloc[1]['amount_of_ingridients'] == 11\n",
    "assert train_X_df.iloc[-6]['amount_of_ingridients'] == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cuisines = <YOUR CODE>\n",
    "recipe_ing_amount_sequence = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's Vizualize using [boxplot](https://ru.wikipedia.org/wiki/%D0%AF%D1%89%D0%B8%D0%BA_%D1%81_%D1%83%D1%81%D0%B0%D0%BC%D0%B8)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![boxplot](https://www.simplypsychology.org/boxplot.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's check boxplot [demo](https://matplotlib.org/3.3.3/gallery/pyplots/boxplot_demo_pyplot.html#sphx-glr-gallery-pyplots-boxplot-demo-pyplot-py) from matplotlib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here you can insert any function\n",
    "sorted_ind = np.argsort([*map(<YOUR CODE>, recipe_ing_amount_sequence)])\n",
    "fig = plt.figure(figsize =(14, 8))   \n",
    "# Creating axes instance \n",
    "ax = fig.add_axes([0, 0, 1, 1]) \n",
    "  \n",
    "# Creating plot \n",
    "<YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But there are a lot of gorgeous libraries for vizualization except matplotlib, for instance - [seaborn](https://seaborn.pydata.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "f, ax = plt.subplots(figsize=(20, 8))\n",
    "sns.boxplot(x='cuisine',\n",
    "            y='amount_of_ingridients',\n",
    "            data=train_X_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction features from data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's remove column with amount of ingridients and go on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's convert list of ingridients to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which separator is better - ?\n",
    "<YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer example (Bag of words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/1239/1*WN18F5oVHKzf_DXcCpSFiQ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "     'This is the first document.',\n",
    "     'This document is the second document.',\n",
    "     'And this is the third one.',\n",
    "     'Is this the first document?',\n",
    " ]\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply to our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = <YOUR CODE>\n",
    "X_train_vec = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names()[::500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec.todense() # transform to usual matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_first_receipe = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(vectorizer.get_feature_names())[indices_first_receipe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.iloc[0]['ingredients'].split('#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if tokenization was correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (np.sort(np.array(vectorizer.get_feature_names())[indices_first_receipe]) ==\n",
    " np.sort(np.array(X_train.iloc[0]['ingredients'].split('#')))).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's inspect our X matrix as Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words_df = pd.DataFrame(X_train_vec.todense(),\n",
    "             columns=vectorizer.get_feature_names())\n",
    "bag_of_words_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check that we transform our data to matrix correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words_df[bag_of_words_df['(   oz.) tomato paste'] != 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df.iloc[bag_of_words_df[bag_of_words_df['(   oz.) tomato paste'] != 0].index]['cuisine']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's add some ~magic~ Machine Learning here! ðŸ”®ðŸ”®ðŸ”®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec = <YOUR CODE>\n",
    "X_val_vec = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_vec.shape, X_val_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![machine learns](https://resources.hacware.com/content/images/2020/08/memeticMemoryheader.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_proba = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the metric (multiclass accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_val, y_val_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert accuracy_score(y_val, y_val_proba) > 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The most convinient way to visualize confusion matrix - to use [plot_confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html), but you can also visualize it by yourself :) You can get matrix with [this method](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_confusion_matrix(reg, X_val_vec, y_val, xticks_rotation='vertical', ax=ax)  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's discuss about what cuisunes do we mix up more?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wow! Impressive!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's predict on test and send to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_proba = reg.predict(test_X)\n",
    "test_proba[::1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumbit_df = test_X_df.copy()\n",
    "<YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumbit_df.to_csv('./bag_of_words_log_regr.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive part (let's cook!) (and check our intuition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_df['ingredients'].to_numpy()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Can we use all ingridients which we can imagine with our approach with bag of words?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_food_in_our_bag_of_words(food_name: str, vect_features_hash_map: ty.Set[str]) -> str:\n",
    "    <YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_food_in_our_bag_of_words('pierogi', vect_features_hash_map) == 'Ok!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in []:\n",
    "    is_food_in_our_bag_of_words(i, vect_features_hash_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whatnot_reciepe = []\n",
    "whatnot_vec = vectorizer.transform(['#'.join(whatnot_reciepe)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try Decision Tree and look up through hyperparams:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Perfect explanation of Explanation of Gini Impurity (eng)](https://victorzhou.com/blog/gini-impurity/)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For iteration of Hyperparams researches often use [GridSearchCV from sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=14)\n",
    "max_depth_array = [2, 4, 8, 16, 32, 64, 128, 256, 512]\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier(random_state=42)\n",
    "grid_dtc = <YOUR CODE>\n",
    "\n",
    "grid_dtc.fit(X_train_vec, y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check feature importance of the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = grid_dtc.best_estimator_.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(bag_of_words_df.shape[1])[:10]:\n",
    "    print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f],\n",
    "                                      bag_of_words_df.columns[indices[f]],\n",
    "                                      importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makePlotOfResultsOfGridSearchCVDependsOnParam(method_name, hyperparam_name, X_axis_label, cv_results_df,\n",
    "                                                  type_of_x_values=float, is_xticks_rotated=False):\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.title(\"GridSearchCV evaluating result ({} method):\".format(method_name), fontsize=16)\n",
    "    ax = plt.gca()\n",
    "\n",
    "    X_axis_data = np.array(cv_results_df[hyperparam_name], dtype=type_of_x_values)\n",
    "    print(X_axis_data)\n",
    "    test_mean = np.array(cv_results_df['mean_test_score'], dtype=float)\n",
    "    train_mean = np.array(cv_results_df['mean_train_score'], dtype=float)\n",
    "    test_std_error = np.array(cv_results_df['std_test_score'], dtype=float)\n",
    "    train_std_error = np.array(cv_results_df['std_train_score'], dtype=float)\n",
    "\n",
    "    ax.fill_between(X_axis_data, test_mean - test_std_error,\n",
    "                    test_mean + test_std_error,\n",
    "                    alpha=0.4, color='red', label='Std error on test data')\n",
    "\n",
    "    ax.fill_between(X_axis_data, train_mean - train_std_error,\n",
    "                    train_mean + train_std_error,\n",
    "                    alpha=0.4, color='green', label='Std error on train data')\n",
    "\n",
    "    ax.plot(X_axis_data, test_mean,\n",
    "            alpha=1,\n",
    "            label=\"test_mean\")\n",
    "    ax.plot(X_axis_data, train_mean,\n",
    "            alpha=1,\n",
    "            label=\"train_mean\")\n",
    "\n",
    "    plt.xlabel(X_axis_label)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc=1)\n",
    "\n",
    "    if is_xticks_rotated:\n",
    "        plt.xticks(rotation=90)\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makePlotOfResultsOfGridSearchCVDependsOnParam('Decision Tree',\n",
    "                                              'param_max_depth',\n",
    "                                              'Depth of trees',\n",
    "                                              grid_dtc.cv_results_\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What can we see here?**\n",
    "<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**(SPOILER)**\n",
    "### Looks like overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to fight?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can decrease complexity of our model, fix optimal depth**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Decision Tree Classifier sklearn Docs](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_leaf_array = np.arange(1, 20)\n",
    "decision_tree = tree.DecisionTreeClassifier(<YOUR CODE>)\n",
    "\n",
    "grid_dtc = <YOUR CODE>\n",
    "\n",
    "grid_dtc.fit(X_train_vec, y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![whats next](https://freecontent.manning.com/wp-content/uploads/Elgendy_tCVPp4_06b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Word2Vec](https://en.wikipedia.org/wiki/Word2vec)\n",
    "- [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)\n",
    "- [LSA](https://en.wikipedia.org/wiki/Latent_semantic_analysis)\n",
    "\n",
    "...\n",
    "\n",
    "NLP approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVM\n",
    "- Boosting (XGboost, CatBoost)\n",
    "- Bagging (Random Forest)\n",
    "- Neural Nets (of course!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tom](https://storage.googleapis.com/kaggle-forum-message-attachments/703594/14673/DATAAC.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}